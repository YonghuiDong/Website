---
title: Writing Efficient R Code
author: ''
date: '2018-02-01'
categories:
  - R
tags:
  - Notes
  - R
slug: writing-efficient-r-code
---



<p>
</p>
<p>My notes on <a href="https://www.datacamp.com/courses/writing-efficient-r-code">Writing Efficient R code</a></p>
<p><strong>1. Use an up-to-date version of R</strong></p>
<p><strong>2. The Art of Benchmarking</strong></p>
<p>In order to make your code go faster, you need to know how long it takes to run. <code>Benchmarking</code> is used to time how long each solution takes, then you can select the fastest.</p>
<ol style="list-style-type: decimal">
<li>Two steps:</li>
</ol>
<ul>
<li><p>construct the function</p></li>
<li><p>time the function</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Two functions:</li>
</ol>
<ul>
<li><p>system.time(). Convenient, but does not allow direct comparing multiple function calls.</p></li>
<li><p>microbenchmark(). Function from microbenchmark package, allows direct comparing multiple function calls.</p></li>
</ul>
<p><strong>3. Fine Tuning: Efficient Base R</strong></p>
<p>R is flexible because you can often solve a single problem in many different ways. Some ways can be several orders of magnitude faster than the others.</p>
<p>In R, memory allocation happens automatically. R allocates memory in RAM to store variables, and it is time consuming. Minimizing variable assignment could improve the speed</p>
<ol style="list-style-type: decimal">
<li>Three important rules:</li>
</ol>
<ul>
<li><p>Rule 1: never ever grow a vector.</p></li>
<li><p>Rule 2: use a vectorised solution wherever possible.</p></li>
<li><p>Rule 3: use a matrix instead of a dataframe whenever appropriate.</p></li>
</ul>
<p><strong>4. Diagnosing Problems: Code Profiling</strong></p>
<p><code>Profiling</code> helps you locate the bottlenecks in your code. The general idea is to run the code and record what is being currently excuted every few milliseconds.</p>
<p>It can be done using Profvis R-package, and this package has been integrated in Rstudio. You can highlight the code that you want to profile.</p>
<p><strong>5. Turbo Charged Code: Parallel Programming</strong></p>
<p>Some problems can be solved faster using multiple cores on your machine. By default, R only uses 1 core.</p>
<ol style="list-style-type: decimal">
<li>How many cores does this machine have?</li>
</ol>
<p>The parallel package has a function detectCores() that determines the number of cores in a machine.</p>
<ol start="2" style="list-style-type: decimal">
<li>What sort of problems benefit from parallel computing?</li>
</ol>
<p>Not every analysis can make use of multiple cores. Many statistical algorithms can only use a single core. If you can run your loop forward and backwards, there is a good chance that you can use multicore computing.</p>
<ol start="3" style="list-style-type: decimal">
<li>The parallel package - parApply() &amp; parSapply() &amp; parLapply()</li>
</ol>
<p>They are the parallel versions of apply(), sapply() &amp; lapply()</p>
<p><strong>6. The examples</strong></p>
<pre class="r"><code>m &lt;- matrix(rnorm(100000), ncol = 10)
d &lt;- as.data.frame(m)
#(1) time and compare a matrix and a dataframe (point 2 and point 3: rule 3)
library(&quot;microbenchmark&quot;)
microbenchmark(apply(m, 1, mean), 
               apply(d, 1, mean), 
               times = 10) # Run each function 10 times</code></pre>
<pre><code>## Unit: milliseconds
##               expr      min       lq     mean   median       uq      max
##  apply(m, 1, mean) 37.86911 43.05239 47.54156 45.05385 48.33339 72.60366
##  apply(d, 1, mean) 44.16448 48.30704 50.05870 49.54362 50.95960 60.98107
##  neval cld
##     10   a
##     10   a</code></pre>
<pre class="r"><code>#(2) Parallel computing (point 5)
# Five steps
library(&quot;parallel&quot;) #(1) Load package
copies_of_r&lt;- detectCores() - 1 #(2) Specify the number of cores
cl &lt;- makeCluster( copies_of_r) #(3) Create a cluster object
m_mean &lt;- parApply(cl, m, 1, mean) #(4) Swap to parApply()
stopCluster(cl) #(5) stop</code></pre>
